{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b094c2f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.models import Sequential,Model\n",
    "from tensorflow.keras.layers import Input\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "#from keras.layers import Conv2D, MaxPooling2D\n",
    "#from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import (\n",
    "    BatchNormalization, SeparableConv2D, MaxPooling2D, Activation, Flatten, Dropout, Dense, Conv2D\n",
    ")\n",
    "from keras.layers import LeakyReLU\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fde48b3",
   "metadata": {},
   "source": [
    "# Leer imágenes \n",
    "\n",
    "Este código está diseñado para recorrer un directorio específico y sus subdirectorios, leer todas las imágenes con extensiones .jpg, .jpeg, .png, .bmp, o .tiff, y almacenar información sobre estas imágenes y los directorios donde se encuentran."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7146a571",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "leyendo imagenes de  C:/Users/HUAWEI/Documents/ITM/ISC 11Onceavo/IA/cnn/dataset\\\n",
      "Directorios leidos: 5\n",
      "Imagenes en cada directorio [31, 324, 218, 129, 0]\n",
      "suma Total de imagenes en subdirs: 702\n"
     ]
    }
   ],
   "source": [
    "dirname = os.path.join(os.getcwd(),'C:/Users/HUAWEI/Documents/ITM/ISC 11Onceavo/IA/cnn/dataset')\n",
    "imgpath = dirname + os.sep \n",
    "\n",
    "images = []\n",
    "directories = []\n",
    "dircount = []\n",
    "prevRoot=''\n",
    "cant=0\n",
    "\n",
    "print(\"leyendo imagenes de \",imgpath)\n",
    "\n",
    "for root, dirnames, filenames in os.walk(imgpath):\n",
    "    for filename in filenames:\n",
    "        if re.search(\"\\\\.(jpg|jpeg|png|bmp|tiff)$\", filename):\n",
    "            cant=cant+1\n",
    "            filepath = os.path.join(root, filename)\n",
    "            image = plt.imread(filepath)\n",
    "            if(len(image.shape)==3):\n",
    "                \n",
    "                images.append(image)\n",
    "\n",
    "    b = \"Leyendo...\" + str(cant)\n",
    "    #print (b, end=\"\\r\")\n",
    "    if prevRoot !=root:\n",
    "        #print(root, cant)\n",
    "        prevRoot=root\n",
    "        directories.append(root)\n",
    "        dircount.append(cant)\n",
    "        cant=0\n",
    "dircount.append(cant)\n",
    "\n",
    "dircount = dircount[1:]\n",
    "dircount[0]=dircount[0]+1\n",
    "print('Directorios leidos:',len(directories))\n",
    "print(\"Imagenes en cada directorio\", dircount)\n",
    "print('suma Total de imagenes en subdirs:',sum(dircount))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "273d4221",
   "metadata": {},
   "source": [
    "# Generación de Etiquetas \n",
    "\n",
    "Esta sección del código está asignando una etiqueta numérica a cada imagen basada en el directorio del que proviene. Si un directorio tiene 5 imágenes, todas esas imágenes tendrán la misma etiqueta (por ejemplo, 0), y luego la etiqueta cambiará para el próximo directorio. Esto es útil para clasificar las imágenes según sus directorios de origen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b68fc058",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad etiquetas creadas:  702\n"
     ]
    }
   ],
   "source": [
    "labels=[]\n",
    "indice=0\n",
    "for cantidad in dircount:\n",
    "    for i in range(cantidad):\n",
    "        labels.append(indice)\n",
    "    indice=indice+1\n",
    "print(\"Cantidad etiquetas creadas: \",len(labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b3715b6",
   "metadata": {},
   "source": [
    "Esta sección del código permite identificar y almacenar los nombres de los subdirectorios de manera organizada, lo cual puede ser útil para el análisis posterior o para referenciar los datos procesados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "46a8e8b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 \n",
      "1 chevy\n",
      "2 march\n",
      "3 sentra\n",
      "4 vocho\n"
     ]
    }
   ],
   "source": [
    "sriesgos=[]\n",
    "indice=0\n",
    "for directorio in directories:\n",
    "    name = directorio.split(os.sep)\n",
    "    print(indice , name[len(name)-1])\n",
    "    sriesgos.append(name[len(name)-1])\n",
    "    indice=indice+1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "065bea08",
   "metadata": {},
   "source": [
    "Esta sección del código convierte las listas de etiquetas e imágenes en arreglos de NumPy para facilitar su manipulación. Luego, identifica las clases únicas presentes en las etiquetas y calcula el número total de clases, imprimiendo esta información. Esto es útil para entender la distribución de las clases en el conjunto de datos y preparar los datos para análisis o entrenamiento de modelos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0433bc93",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence. The requested array has an inhomogeneous shape after 3 dimensions. The detected shape was (701, 21, 28) + inhomogeneous part.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(labels)\n\u001b[1;32m----> 2\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muint8\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m#convierto de lista a numpy\u001b[39;00m\n\u001b[0;32m      4\u001b[0m classes \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(y)\n\u001b[0;32m      5\u001b[0m nClasses \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(classes)\n",
      "\u001b[1;31mValueError\u001b[0m: setting an array element with a sequence. The requested array has an inhomogeneous shape after 3 dimensions. The detected shape was (701, 21, 28) + inhomogeneous part."
     ]
    }
   ],
   "source": [
    "y = np.array(labels)\n",
    "X = np.array(images, dtype=np.uint8) #convierto de lista a numpy\n",
    "\n",
    "classes = np.unique(y)\n",
    "nClasses = len(classes)\n",
    "print('Total number of outputs : ', nClasses)\n",
    "print('Output classes : ', classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a7d714",
   "metadata": {},
   "source": [
    "Esta sección del código divide el conjunto de datos en dos partes: datos de entrenamiento (80%) y datos de prueba (20%). Luego, imprime las dimensiones de estos conjuntos de datos. Esta división es crucial en el proceso de entrenamiento y evaluación de modelos de aprendizaje automático, ya que permite evaluar el rendimiento del modelo en datos no vistos durante el entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2616370",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X,test_X,train_Y,test_Y = train_test_split(X,y,test_size=0.2)\n",
    "print('Training data shape : ', train_X.shape, train_Y.shape)\n",
    "print('Testing data shape : ', test_X.shape, test_Y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fa84503",
   "metadata": {},
   "source": [
    "Esta sección del código utiliza Matplotlib para mostrar las primeras imágenes de los conjuntos de datos de entrenamiento y de prueba, junto con sus etiquetas correspondientes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c01b1c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[5,5])\n",
    "\n",
    "# Display the first image in training data\n",
    "plt.subplot(121)\n",
    "plt.imshow(train_X[0,:,:], cmap='gray')\n",
    "plt.title(\"Ground Truth : {}\".format(train_Y[0]))\n",
    "\n",
    "# Display the first image in testing data\n",
    "plt.subplot(122)\n",
    "plt.imshow(test_X[0,:,:], cmap='gray')\n",
    "plt.title(\"Ground Truth : {}\".format(test_Y[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd95124",
   "metadata": {},
   "source": [
    "Esta sección del código convierte los datos de imágenes a tipo de dato float32 y normaliza los valores de píxel para que estén en el rango [0, 1]. Luego, visualiza una imagen del conjunto de datos de prueba. La normalización es crucial para el entrenamiento efectivo de modelos de aprendizaje automático."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb879f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "rain_X = train_X.astype('float32')\n",
    "test_X = test_X.astype('float32')\n",
    "train_X = train_X/255.\n",
    "test_X = test_X/255.\n",
    "plt.imshow(test_X[0,:,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6b36b8e",
   "metadata": {},
   "source": [
    "Esta sección del código convierte las etiquetas de clase en formato entero a un formato de codificación one-hot. Esto es importante porque muchos algoritmos de aprendizaje automático, especialmente las redes neuronales, funcionan mejor con etiquetas en formato one-hot. Luego, se imprime una etiqueta antes y después de la conversión para verificar el proceso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ee7f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_Y_one_hot = to_categorical(train_Y)\n",
    "test_Y_one_hot = to_categorical(test_Y)\n",
    "print('Original label:', train_Y[0])\n",
    "print('After conversion to one-hot:', train_Y_one_hot[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "904894e9",
   "metadata": {},
   "source": [
    "Esta sección del código toma el conjunto de datos de entrenamiento y lo divide en dos conjuntos: uno para continuar el entrenamiento y otro para la validación. La validación es una parte crucial del proceso de entrenamiento de modelos de aprendizaje automático porque permite evaluar el rendimiento del modelo en datos no vistos durante el entrenamiento, ayudando a prevenir el sobreajuste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28f6f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mezclar todo y crear los grupos de entrenamiento y testing\n",
    "train_X,valid_X,train_label,valid_label = train_test_split(train_X, train_Y_one_hot, test_size=0.2, random_state=13)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c61a50",
   "metadata": {},
   "source": [
    "Esta sección del código es útil para verificar que los conjuntos de datos se han dividido correctamente y que las formas de los datos son las esperadas. Esto asegura que los datos estén listos para ser utilizados en el entrenamiento y validación del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd3618b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_X.shape,valid_X.shape,train_label.shape,valid_label.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a41f06f",
   "metadata": {},
   "source": [
    "Esta sección del código define y configura varios parámetros importantes para el entrenamiento de una red neuronal. Estos parámetros incluyen la tasa de aprendizaje inicial, el número de épocas y el tamaño del lote."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea432f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#declaramos variables con los parámetros de configuración de la red\n",
    "INIT_LR = 1e-3 # Valor inicial de learning rate. El valor 1e-3 corresponde con 0.001\n",
    "epochs = 20 # Cantidad de iteraciones completas al conjunto de imagenes de entrenamiento\n",
    "batch_size = 64 # cantidad de imágenes que se toman a la vez en memoria"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e3011de",
   "metadata": {},
   "source": [
    "Esta sección del código define un modelo de red neuronal convolucional (CNN) utilizando la API de Keras. La red consta de varias capas, incluyendo capas convolucionales, de activación, de pooling, de normalización (Dropout) y densas (fully connected)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e931725",
   "metadata": {},
   "outputs": [],
   "source": [
    "riesgo_model = Sequential()\n",
    "riesgo_model.add(Conv2D(32, kernel_size=(3, 3),activation='linear',padding='same',input_shape=(21,28,3)))\n",
    "riesgo_model.add(LeakyReLU(alpha=0.1))\n",
    "riesgo_model.add(MaxPooling2D((2, 2),padding='same'))\n",
    "riesgo_model.add(Dropout(0.5))\n",
    "\n",
    "riesgo_model.add(Flatten())\n",
    "riesgo_model.add(Dense(32, activation='linear'))\n",
    "riesgo_model.add(LeakyReLU(alpha=0.1))\n",
    "riesgo_model.add(Dropout(0.5))\n",
    "riesgo_model.add(Dense(nClasses, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ef9310",
   "metadata": {},
   "outputs": [],
   "source": [
    "riesgo_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40d22b30",
   "metadata": {},
   "source": [
    "Esta sección del código configura la función de pérdida, el optimizador y las métricas que se utilizarán durante el entrenamiento del modelo. La compilación del modelo es un paso crucial que prepara el modelo para ser entrenado con los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a8c94ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "riesgo_model.compile(loss=keras.losses.categorical_crossentropy, optimizer=tf.keras.optimizers.SGD(learning_rate=INIT_LR, decay=INIT_LR / 100),metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d98a4477",
   "metadata": {},
   "source": [
    "\n",
    "Esta sección del código entrena el modelo de red neuronal convolucional utilizando los datos de entrenamiento. Durante el entrenamiento, el modelo se ajusta iterativamente a los datos, actualizando sus parámetros para minimizar la función de pérdida. El conjunto de datos de validación se utiliza para monitorear el rendimiento del modelo y prevenir el sobreajuste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da257d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "riesgo_train = riesgo_model.fit(train_X, train_label, batch_size=batch_size,epochs=epochs,verbose=1,validation_data=(valid_X, valid_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d990b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "riesgo_model.save(\"C:/Users/HUAWEI/Documents/ITM/ISC 11Onceavo/IA/cnn/autos.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e5126d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eval = riesgo_model.evaluate(test_X, test_Y_one_hot, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6347b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Test loss:', test_eval[0])\n",
    "print('Test accuracy:', test_eval[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "525f2cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = riesgo_train.history['accuracy']\n",
    "val_accuracy = riesgo_train.history['val_accuracy']\n",
    "loss = riesgo_train.history['loss']\n",
    "val_loss = riesgo_train.history['val_loss']\n",
    "epochs = range(len(accuracy))\n",
    "plt.plot(epochs, accuracy, 'bo', label='Training accuracy')\n",
    "plt.plot(epochs, val_accuracy, 'b', label='Validation accuracy')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e46e6d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_classes2 = riesgo_model.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b9cd1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_classes=[]\n",
    "for predicted_riesgo in predicted_classes2:\n",
    "    predicted_classes.append(predicted_riesgo.tolist().index(max(predicted_riesgo)))\n",
    "predicted_classes=np.array(predicted_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "270be2d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_classes.shape, test_Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e3582c",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = np.where(predicted_classes==test_Y)[0]\n",
    "print(\"Found %d correct labels\" % len(correct))\n",
    "for i, correct in enumerate(correct[0:9]):\n",
    "    plt.subplot(3,3,i+1)\n",
    "    plt.imshow(test_X[correct].reshape(21,28,3), cmap='gray', interpolation='none')\n",
    "    plt.title(\"{}, {}\".format(sriesgos[predicted_classes[correct]],\n",
    "                                                    sriesgos[test_Y[correct]]))\n",
    "\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa18a7ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "incorrect = np.where(predicted_classes!=test_Y)[0]\n",
    "print(\"Found %d incorrect labels\" % len(incorrect))\n",
    "for i, incorrect in enumerate(incorrect[0:9]):\n",
    "    plt.subplot(3,3,i+1)\n",
    "    plt.imshow(test_X[incorrect].reshape(21,28,3), cmap='gray', interpolation='none')\n",
    "    plt.title(\"{}, {}\".format(sriesgos[predicted_classes[incorrect]],\n",
    "                                                    sriesgos[test_Y[incorrect]]))\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7836cb99",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_names = [\"Class {}\".format(i) for i in range(nClasses)]\n",
    "print(classification_report(test_Y, predicted_classes, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d654fde2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.transform import resize\n",
    "\n",
    "images=[]\n",
    "# AQUI ESPECIFICAMOS UNAS IMAGENES\n",
    "filenames = ['C:/Users/HUAWEI/Documents/ITM/ISC 11Onceavo/IA/cnn/vocho.jpg']\n",
    "\n",
    "for filepath in filenames:\n",
    "    image = plt.imread(filepath,0)\n",
    "    image_resized = resize(image, (21, 28),anti_aliasing=True,clip=False,preserve_range=True)\n",
    "    images.append(image_resized)\n",
    "\n",
    "X = np.array(images, dtype=np.uint8) #convierto de lista a numpy\n",
    "test_X = X.astype('float32')\n",
    "test_X = test_X / 255.\n",
    "\n",
    "predicted_classes = riesgo_model.predict(test_X)\n",
    "\n",
    "for i, img_tagged in enumerate(predicted_classes):\n",
    "    print(filenames[i], sriesgos[img_tagged.tolist().index(max(img_tagged))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af7ea5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.transform import resize\n",
    "from keras.models import load_model\n",
    "\n",
    "# Cargar el modelo h5\n",
    "modelo_h5 = 'C:/Users/HUAWEI/Documents/ITM/ISC 11Onceavo/IA/cnn/autos.h5'\n",
    "riesgo_model = load_model(modelo_h5)\n",
    "\n",
    "images = []\n",
    "# AQUI ESPECIFICAMOS UNAS IMAGENES\n",
    "filenames = ['C:/Users/HUAWEI/Documents/ITM/ISC 11Onceavo/IA/cnn/sentra.jpg\"']\n",
    "\n",
    "for filepath in filenames:\n",
    "    image = plt.imread(filepath)\n",
    "    image_resized = resize(image, (21, 28), anti_aliasing=True, clip=False, preserve_range=True)\n",
    "    images.append(image_resized)\n",
    "\n",
    "X = np.array(images, dtype=np.uint8)  # Convierto de lista a numpy\n",
    "test_X = X.astype('float32')\n",
    "test_X = test_X / 255.\n",
    "\n",
    "predicted_classes = riesgo_model.predict(test_X)\n",
    "\n",
    "# Asegúrate de tener una lista de etiquetas o categorías en 'sriesgos'\n",
    "sriesgos = ['sentra', 'vocho', 'chevy']  # Reemplaza con tus etiquetas reales\n",
    "\n",
    "for i, img_tagged in enumerate(predicted_classes):\n",
    "    print(filenames[i], sriesgos[np.argmax(img_tagged)])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
